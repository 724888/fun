### Encoding and Evolution 数据编码和程序演化     

很少有程序的一次性就写好后期不变化的。新功能的添加都意味着就程序要改变。 并且大多数情况下数据也要随着程序改变。可能需要    
添加新的字段，可能需要用新的方式来保存。在系统设计之初 应该让系统变得够灵活。以适应后面的一些变化。     

如果使用关系数据库的话是通过alter来改变。 如果是文档型数据库的话 要考虑到文档数据库 读时模式的特点。数据可能混合了   
新的数据格式 和 旧的格式。这个时候就要考虑兼容性了。     

**兼容性：**    

* 向后兼容     

新版本的代码理解旧版本的数据。

* 向前兼容    

旧版本的代码来理解新版本的数据,这种兼容方式会麻烦点。从这里也引出了各种数据编码格式。   

### 数据编码格式      

下面说到的有 json xml Protocol Buffers，Thrift和Avro。 格式说完后还会说 如何通过这些来进行通信和存储。     

广义来讲程序主要用两种格式，一种是内存中直接使用的，另一种是通信 存储用的。      

内存中数据存在 列表 数组 字典 结构体 对象中     

保存在文件中对其持久化就需要进行encode 例如 json xml 等..

### 语言特定的格式     

很多编程语言都有序列化支持，python 中有pickle， java中有java.io.Serializable。 这些方法在各自的语言中    
可以很好的使用，但是很多时候这些工具是和语言绑死在一起的，如果只是很简单的用一下 用这些内置的编码也无妨，    
但是如何数据会被频繁使用，并且可能会和其他系统交互 就要考虑使用其它更为通用的编码方式了。     


### json xml csv 二进制编码    

先来看 json（JS 对象标记） 和 xml（可扩展标记语言） csv     

**json xml csv 对比**
    
    xml    element、attribute和element content。
    json   object、array、string、number、boolean(true/false)和null。
    csv  逗号分割的数据
    
    为什么有时候json更好用？
    
    表现一个学生对象
    
    每个 key value 用属性来表示是可以的，但是如果value也是一个object 就无法作为属性（attribute）来表示。
    <student name="John" age="10">
        <address>
            <country>China</country>
            <province>Guang Dong</province>
            <city>...</city>
            <district>...</district>
            ...
        </address>
    </student>

    反观json 可以很自然的映射
    {
        "name": "John",
        "age" : 10,
        "address" : {
            "country" : "China",
            "province" : "Guang Dong",
            "city" : "..",
            "district" : "..",
            ...
        }
    }

    另外 xml映射数组tag会冗余很多。
    
    xml 比json 好的地方。
    有规范的xpath支持，在很复杂的数据中找到自己需要的数据会比较容易。

**其它问题**  

1. 数字的编码多有歧义之处。XML和CSV不能区分数字和字符串（除非引用外部模式）。      
JSON虽然区分字符串和数字，但不区分整数和浮点数，而且不能指定精度。    

2. json xml 对unicode支持很好的支持，但是对二进制串支持不好。 这一点可以通过base64     
来转换，但是增加了数据的大小。    

3. csv 的格式比较模糊，如果一个值包含了逗号，或者换行符。 这个要如何处理（csv是通过逗号来将值分割的。）

json，csv，xml 虽然有一些缺陷，但是最大的问题不是在于这些，最大的问题是让不同的人认可一套工具来使用。     
开始实习后接触了很多的接口，遇到的json 和 xml各占一半。使用的静态数据的话基本都是csv 和 json格式的。      
如果对方给的csv格式的数据并不是那么规范的话，处理起来很蛋疼。。


 
### 二进制编码      

当数据到达一个规模后，不同的数据格式的选择就会带来很大的影响。常用的mongodb 使用的数据格式就是类似json的bson。    

**Thrift与Protocol Buffers ,Avro** 这三种编码的共同点都是有一个预先的schema来定义数据的格式，在后面保存数据的时候     
一些重复的字段就不需要再次保存了。 通过这种方式来减少空间。    

主要来看下avro这种方式，看一个它如何支持模式演变的。    

使用avro 来写的模式语言如下：    

    record Person {
        string                userName;
        union { null, long }  favoriteNumber = null;
        array<string>         interests;
    }

    等价的json

    {
        "type": "record",
        "name": "Person",
        "fields": [
            {"name": "userName", "type": "string"},
            {"name": "favoriteNumber", "type": ["null", "long"], "default": null},
            {"name": "interests", "type": {"type": "array", "items": "string"}
        ] 
    }

**avro 如何支持模式演变的？**      

读者模式 和 写者模式， 读者模式指的是要解码数据的时候（从网络 数据库 文件读取）， 这些数据是在某一个    
模式中的。 而写者模式是 编码的时候，用它知道的模式来编码。      

模式演变的关键也就在于 读者模式 和 写者模式不必相同，只需要兼容就可以了。
如果读取数据的时候，遇到在写者模式中出现，而不在读者模式中出现的就忽略，如果在读者模式出现，不在写者模式的     
就填充默认值。 

![](http://pyblog-10073407.image.myqcloud.com/postimage1521375334?imageView2/0/w/450/h/400)


#### 模式演变的规则     

上面也提到了 向前兼容就是前面的代码来兼容后面的数据。 向后兼容正好相反。 使用avro的时候是这样子做的      
向前兼容： 使用新版本的架构作为写者，而旧版本的作为读者。 向后兼容则是用新版本的作为读者， 写者作为旧版本。      

并且在保证兼容性的时候只可以添加 删除有默认值的字段，试想如果添加了一个没有默认值的字段，新的阅读器无法读取     
旧作者写的数据。如果把默认的数据删除掉，旧的阅读器也无法读取新的写者的数据。

这些schema 都可以集中保存在一个地方，当程序出现变化的时候处理起来也很方便。并且在avro中 读的schema 和 写的schema    
是可以不同的，avro会自己进行映射。 对于静态语言来说avro可以自动生成这些语言的代码，并且在编译的时候还原数据。       

    二进制编码的好处：     
    比二进制json更省空间（主要是省略了字段名）
    对于静态语言来说，可以直接从模型生成代码
    可以保证向前 向后兼容
    


#### 数据流

有一些数据可能是在A进程处理完后发送到B进程进行处理。A B进程可能不是共享一个内存空间的。这时     
就需要把数据通过网络（A进程 encode---网络---decode B进程）来处理。 兼容性就是 A B 两端的一个关系。     

常见的有三种方式：   
* 通过数据库   
* 通过服务调用 rpc rest
* 异步消息传输

**数据库中的数据流**    




     

